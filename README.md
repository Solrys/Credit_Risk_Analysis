# Credit_Risk_Analysis
Creating models analyzing credit risk


## Background
Loans are an essential part of modern society

On one hand loans create revenue not the other hand there is a risk involved if loan owners do not meet their financial obligations
Creating models can help us analyze the risk involved before granting a loan. 
Machine Learning helps us analyze accuray, sensitivy, oversampling, and underspamling, among other useful algorithms. 
Machine learning teaches us how to deal withthe personal aspect a well.


## Objectives

* Explain how a machine learning algorithm is used in data analytics.
* Create training and test groups from a given data set.
* Implement the logistic regression, decision tree, random forest, and support vector machine algorithms.
* Interpret the results of the logistic regression, decision tree, random forest, and support vector machine algorithms.
* Compare the advantages and disadvantages of each supervised learning algorithm.
* Determine which supervised learning algorithm is best used for a given data set or scenario.
* Use ensemble and resampling techniques to improve model performance.
 


## Method
The purpose of this analysis was to create a supervised machine learning model that could accurately predict credit risk. In order to complete this task, I used 6 different methods, which are:
1. Naive Random Oversampling
2. SMOTE Oversampling
3. Cluster Centroid Undersampling
4. SMOTEENN Sampling
5. Balanced Random Forest Classifying
6. Easy Ensemble Classifying
Through each of these methods, I split my data into training and testing datasets, and compiled accuracy scores, confusion matries, and classification reports as my results.

(enamble)This model outperformed the platform from which to continue to be approved. We have the leading balanced accuracy that we have encountered. Along with high-risk precision, recall and, therefore F1 score. This model is furhter efficient than the others. My recommendation is looking beneath into the data set at the fasle positives and false negatives. My guess there is a factor here that is being given more weight or not enough that could be used to train the model to improve the output.

